# Excercise 5.18
set.seed(42)   # ensure reproducibility
x <- c(1,3)
n <- length(x)
B <- 10000    # number of bootstrap replicates

# Original sample variance 
S2 <- var(x)

# Bootstrap resampling and computation of S*²
boot_S2 <- numeric(B)
for (b in 1:B) {
  xb <- sample(x, n, replace = TRUE)
  boot_S2[b] <- var(xb)
}

# Bootstrap estimate of Var(S²)
boot_var_S2 <- var(boot_S2)

# Display results
cat("Original sample variance S² =", round(S2, 4), "\n")
cat("Bootstrap estimate of Var(S²) ≈", round(boot_var_S2, 4), "\n")

# Excercise 5.19
set.seed(42)   # ensure reproducibility
x <- c(5, 4, 9, 6, 21, 17, 11, 20, 7, 10, 21, 15, 13, 16, 8)
n <- length(x)
B <- 10000    # number of bootstrap replicates

# Original sample variance 
S2 <- var(x)

# Bootstrap resampling and computation of S*²
boot_S2 <- numeric(B)
for (b in 1:B) {
  xb <- sample(x, n, replace = TRUE)
  boot_S2[b] <- var(xb)
}

# Bootstrap estimate of Var(S²)
boot_var_S2 <- var(boot_S2)

# Display results
cat("Original sample variance S² =", round(S2, 4), "\n")
cat("Bootstrap estimate of Var(S²) ≈", round(boot_var_S2, 4), "\n")

# Part B
# Problem 1
# (ii)
load("Assignment 4.RData")
n <- length(x)
xbar <- mean(x)
meanlog <- mean(log(x))
s <- log(xbar) - meanlog
f <- function(a) log(a) - digamma(a) - s

sol <- uniroot(f, c(0.1, 100))
alpha_hat <- sol$root
lambda_hat <- alpha_hat / xbar
cat(sprintf("alpha_hat = %.6f, lambda_hat = %.6f\n", alpha_hat, lambda_hat))

# (iii)
# Fisher information at (alpha_hat, lambda_hat)
I_mat <- matrix(c(
  trigamma(alpha_hat),   -1 / lambda_hat,
  -1 / lambda_hat,        alpha_hat / (lambda_hat^2)
), nrow = 2, byrow = TRUE) * n

# Asymptotic covariance of (alpha_hat, lambda_hat)
V_asym <- solve(I_mat) / n

var_alpha_hat  <- V_asym[1, 1]
var_lambda_hat <- V_asym[2, 2]
sd_alpha_hat   <- sqrt(var_alpha_hat)
sd_lambda_hat  <- sqrt(var_lambda_hat)

cat(sprintf("Var(alpha_hat)  ≈ %.6e;  SD ≈ %.6f\n", var_alpha_hat,  sd_alpha_hat))
cat(sprintf("Var(lambda_hat) ≈ %.6e;  SD ≈ %.6f\n", var_lambda_hat, sd_lambda_hat))

# (iv)
## Setup
load("Assignment 4.RData")
stopifnot(exists("x"), all(x > 0))
set.seed(123)

n       <- length(x)
xbar    <- mean(x)
meanlog <- mean(log(x))
s       <- log(xbar) - meanlog

# One bootstrap iteration: resample → solve for α̂*, λ̂*
boot_once <- function(x){
  xb <- sample(x, length(x), replace = TRUE)
  n  <- length(xb)
  xbar_b    <- mean(xb)
  meanlog_b <- mean(log(xb))
  s_b       <- log(xbar_b) - meanlog_b
  f_b <- function(a) log(a) - digamma(a) - s_b
  
  # Error handling
  a_hat <- tryCatch(uniroot(f_b, c(1e-4, 1e4), tol = 1e-10)$root,
                    error = function(e) NA_real_)
  if (!is.finite(a_hat)) return(c(NA, NA))
  l_hat <- a_hat / xbar_b
  c(a_hat, l_hat)
}

B_list <- c(50, 100, 200, 400, 800, 1600)

boot_results <- lapply(B_list, function(B){
  ests <- replicate(B, boot_once(x))
  a_vec <- ests[1, ]
  l_vec <- ests[2, ]
  c(B = B,
    Var_alpha_boot  = var(a_vec),
    Var_lambda_boot = var(l_vec),
    Var_alpha_hat  = var_alpha_hat,
    Var_lambda_hat = var_lambda_hat)
})

tbl <- do.call(rbind, boot_results)
tbl <- as.data.frame(tbl)
# Sorting and formatting
tbl$B <- as.integer(tbl$B)

print(tbl, row.names = FALSE, digits = 6)

# Problem 2
# (i)set.seed(42)

# MLE for Gamma(α, λ)
gamma_mle <- function(x) {
  # Solve log(alpha) - digamma(alpha) = log(mean(x)) - mean(log(x))
  n <- length(x)
  xbar <- mean(x)
  s <- log(xbar) - mean(log(x))
  f <- function(a) log(a) - digamma(a) - s
  
  # Error handling
  a_hat <- tryCatch(uniroot(f, c(1e-4, 1e4), tol = 1e-10)$root,
                    error = function(e) NA_real_)
  if (!is.finite(a_hat)) return(c(NA, NA))
  l_hat <- a_hat / xbar
  c(a_hat, l_hat)
}

#  Fisher information (sample size n) and Var(α̂)
asymp_var_alpha <- function(alpha, lambda, n) {
  I_n <- matrix(c(trigamma(alpha), -1/lambda,
                  -1/lambda,        alpha/lambda^2),
                nrow = 2, byrow = TRUE) * n
  V <- solve(I_n)   
  V[1, 1]           # Var(α̂)
}


#  Bootstrap
boot_var_alpha <- function(x, B = 1000) {
  n <- length(x)
  a_star <- numeric(B)
  for (b in 1:B) {
    xb <- sample(x, n, replace = TRUE)
    a_star[b] <- gamma_mle(xb)[1]
  }
  var(a_star)   # bootstrap estimate of Var(α̂)
}

# 4) Monte Carlo main loop

run_once <- function(n = 100, B = 1000, alpha_true = 3, lambda_true = 1.5) {
  x <- rgamma(n, shape = alpha_true, rate = lambda_true)
  mle <- gamma_mle(x)
  a_hat <- mle[1]; l_hat <- mle[2]
  
  if (!is.finite(a_hat) || !is.finite(l_hat)) {
    return(c(alpha_hat = NA_real_, var_asym = NA_real_, var_boot = NA_real_))
  }
  
  sig2_asym <- asymp_var_alpha(a_hat, l_hat, n)
  sig2_boot <- boot_var_alpha(x, B)
  c(alpha_hat = a_hat, var_asym = sig2_asym, var_boot = sig2_boot)
}

# Parameters
n <- 100
B <- 1000
R <- 1000
alpha_true <- 3
lambda_true <- 1.5

# Storage
alpha_hat_R <- numeric(R)
var_asym_R  <- numeric(R)
var_boot_R  <- numeric(R)

# Progress 
pb <- txtProgressBar(min = 0, max = R, style = 3)

for (r in 1:R) {
  res <- run_once(n, B, alpha_true, lambda_true)
  alpha_hat_R[r] <- res["alpha_hat"]
  var_asym_R[r]  <- res["var_asym"]
  var_boot_R[r]  <- res["var_boot"]
  if (r %% 10 == 0) setTxtProgressBar(pb, r)
}
close(pb)

#  Summaries required by the assignment
# (A) Sample variance of α̂1,…,α̂R
sample_var_alpha <- var(alpha_hat_R)

# (B) Average of asymptotic variance estimates
avg_asym_var <- mean(var_asym_R)

# (C) Average of bootstrap variance estimates
avg_boot_var <- mean(var_boot_R)

# Tidy table
out <- data.frame(
  Quantity = c("Sample Var of alpha_hat",
               "Average Asymptotic Var estimate",
               "Average Bootstrap Var estimate"),
  Value = c(sample_var_alpha, avg_asym_var, avg_boot_var)
)

print(out, row.names = FALSE)

(ii)
#--- Benchmarks from (i)
sample_var_alpha <- var(alpha_hat_R, na.rm = TRUE)
avg_asym_var     <- mean(var_asym_R,  na.rm = TRUE)
avg_boot_var     <- mean(var_boot_R,  na.rm = TRUE)

#--- Comparison table
cmp <- data.frame(
  Quantity = c("MC sample Var(α̂)", "Avg asymptotic Var", "Avg bootstrap Var"),
  Value    = c(sample_var_alpha,     avg_asym_var,        avg_boot_var)
)

# 差異與相對誤差（以 MC sample Var 當基準）
cmp$Diff_from_MC <- cmp$Value - sample_var_alpha
cmp$Rel_Error    <- cmp$Diff_from_MC / sample_var_alpha

print(cmp, row.names = FALSE, digits = 6)

#--- 哪個更接近基準？（在兩個估計法之間選，排除第一列基準）
which_closer <- c("Asymptotic","Bootstrap")[ which.min(abs(cmp$Diff_from_MC[2:3])) ]
cat(sprintf("\nCloser to MC sample Var: %s\n", which_closer))
